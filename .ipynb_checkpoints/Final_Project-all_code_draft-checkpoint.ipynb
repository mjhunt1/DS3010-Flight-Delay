{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rdeo6F7vRrbf"
   },
   "source": [
    "Flight Analysis\n",
    "\n",
    "Profs notes on the draft: Excellent plan. It will be great to report/show pre-COVID vs. after-COVID analysis (and... even during the COVID in each month/quarterly). You can also try both linear and non-linear regression models (e.g., linear regression and SVR regression with nonlinear kernel). https://scikit-learn.org/stable/auto_examples/svm/plot_svm_regression.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sZLmdTAeR8J2"
   },
   "source": [
    "The data: \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "agyrsdlnzozr"
   },
   "source": [
    "**All imports needed to run**\n",
    "\n",
    "If the next snippet fails, go into Runtime>> Restars Runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "469uSGAKREZ-",
    "outputId": "d4abef10-1f74-4926-db78-cb8540380739"
   },
   "outputs": [],
   "source": [
    "#Only Needs to be run once\n",
    "# import sys\n",
    "# !{sys.executable} -m pip install pymongo\n",
    "# !{sys.executable} -m pip install dnspython==2.1.0\n",
    "# !{sys.executable} -m pip install scikit-learn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymongo\n",
    "import dns\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.metrics import mean_squared_error, r2_score, accuracy_score\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import joblib\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p1owAQjB0Fl2"
   },
   "source": [
    "**Importing Data into MongoDB**\n",
    "\n",
    "We downloaded the data from the website <<INSERT HERE>>\n",
    "\n",
    "We tried loading it through Drive/Google Drive to MongoDB. However, our notebook was not able to handle the amount of data, because it ran out of space.\n",
    "\n",
    "So we used, MongoDB Compass to upload the existing CSVs to our collection\n",
    "    \n",
    "We made a duplicate of the original datatset, because our work requires deleting some values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h5k1Ojmuz9s2"
   },
   "source": [
    "**Connecting to MongoDB**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "VL4X4n-RWFnz"
   },
   "outputs": [],
   "source": [
    "# RUN\n",
    "client = pymongo.MongoClient(\"mongodb+srv://dbUser:test123@cluster0.92wx0.mongodb.net/finalProject?retryWrites=true&w=majority\")\n",
    "\n",
    "db = client['finalProject']\n",
    "\n",
    "collection = db['flightData']\n",
    "\n",
    "# pipeline = [ {\"$match\": {}}, {\"$out\": \"anotheDuplicate\"},]\n",
    "# collection.aggregate(pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DELETING DATA**\n",
    "Deleting the data, which has no values for any of the analysis factors needed below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pymongo.results.DeleteResult at 0x20a1314f700>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Only Needs to be run once\n",
    "# collection.delete_many({'MONTH' : '6' } )\n",
    "# collection.delete_many({'MONTH' : '7' } )\n",
    "# collection.delete_many({'DEP_DELAY' : {'$eq': None}} )\n",
    "# collection.delete_many({'DEP_DELAY_GROUP' : {'$eq': None}} )\n",
    "# collection.delete_many({'ARR_DELAY_GROUP' : {'$eq': None}} )\n",
    "# collection.delete_many({'YEAR' : {'$eq': None}} )\n",
    "# collection.delete_many({'ORIGIN_AIRPORT_ID' : {'$eq': None}} )\n",
    "# collection.delete_many({'DEST_AIRPORT_ID' : {'$eq': None}} )\n",
    "# collection.delete_many({'DEP_TIME' : {'$eq': None}} )\n",
    "# collection.delete_many({'ARR_TIME' : {'$eq': None}} )\n",
    "# collection.delete_many({'ORIGIN' : {'$eq': None}} )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(collection.count_documents({}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QszVHK_U0rS4"
   },
   "source": [
    "**Looking at Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5vcKD-yAwsvp",
    "outputId": "7973b39c-2e21-4331-9e3d-b4fd73060f40"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of data for Pre-Covid: June, July, August of 2019\n",
      "645351\n",
      "\n",
      "Number of data for Covid: June, July, August of 2020\n",
      "371969\n",
      "\n",
      "Example of one data point\n",
      "{'_id': ObjectId('608de2ba9c0bff4d24c42081'), 'YEAR': '2019', 'QUARTER': '3', 'MONTH': '8', 'DAY_OF_MONTH': '25', 'DAY_OF_WEEK': '7', 'FL_DATE': '2019-08-25', 'OP_UNIQUE_CARRIER': 'WN', 'TAIL_NUM': 'N433LV', 'OP_CARRIER_FL_NUM': '4349', 'ORIGIN_AIRPORT_ID': '11292', 'ORIGIN_AIRPORT_SEQ_ID': '1129202', 'ORIGIN_CITY_MARKET_ID': '30325', 'ORIGIN': 'DEN', 'ORIGIN_CITY_NAME': 'Denver, CO', 'ORIGIN_STATE_ABR': 'CO', 'ORIGIN_STATE_NM': 'Colorado', 'DEST_AIRPORT_ID': '13232', 'DEST_AIRPORT_SEQ_ID': '1323202', 'DEST_CITY_MARKET_ID': '30977', 'DEST': 'MDW', 'DEST_CITY_NAME': 'Chicago, IL', 'DEST_STATE_ABR': 'IL', 'DEST_STATE_NM': 'Illinois', 'CRS_DEP_TIME': '2150', 'DEP_TIME': '2150', 'DEP_DELAY': '0.00', 'DEP_DELAY_NEW': '0.00', 'DEP_DEL15': '0.00', 'DEP_DELAY_GROUP': '0', 'DEP_TIME_BLK': '2100-2159', 'TAXI_OUT': '12.00', 'WHEELS_OFF': '2202', 'WHEELS_ON': '0049', 'TAXI_IN': '3.00', 'CRS_ARR_TIME': '0105', 'ARR_TIME': '0052', 'ARR_DELAY': '-13.00', 'ARR_DELAY_NEW': '0.00', 'ARR_DEL15': '0.00', 'ARR_DELAY_GROUP': '-1', 'ARR_TIME_BLK': '0001-0559', 'CANCELLED': '0.00', 'DIVERTED': '0.00', 'CRS_ELAPSED_TIME': '135.00', 'ACTUAL_ELAPSED_TIME': '122.00', 'DISTANCE': '895.00', 'DISTANCE_GROUP': '4'}\n"
     ]
    }
   ],
   "source": [
    "#Just Checking\n",
    "allPreCovid = collection.find({'YEAR':'2019'})\n",
    "allCovid = collection.find({'YEAR':'2020'})\n",
    "\n",
    "print(\"Number of data for Pre-Covid: June, July, August of 2019\")\n",
    "#print(allPreCovid.count())\n",
    "print(collection.count_documents({'YEAR':'2019'}))\n",
    "\n",
    "print()\n",
    "print(\"Number of data for Covid: June, July, August of 2020\")\n",
    "#print(allCovid.count())\n",
    "print(collection.count_documents({'YEAR':'2020'}))\n",
    "\n",
    "print()\n",
    "print(\"Example of one data point\")\n",
    "print(collection.find_one())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vh7ZJs5B2wWr"
   },
   "source": [
    "**Analyzing**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoding(year, enc):\n",
    "    origin = collection.find({'YEAR':year},{'_id':0,enc:1})\n",
    "    ids = []\n",
    "    for doc in origin:\n",
    "        ids+=[(doc.get(enc))]\n",
    "    return ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ENCODINGS 2019\n",
    "\n",
    "leOrigin = preprocessing.LabelEncoder()\n",
    "ids = encoding('2019', 'ORIGIN')\n",
    "encOrigin19 =leOrigin.fit_transform(ids)\n",
    "\n",
    "le_dictOrigin19 = dict(zip(leOrigin.classes_, leOrigin.transform(leOrigin.classes_)))\n",
    "\n",
    "leDeptTime = preprocessing.LabelEncoder()\n",
    "ids = encoding('2019', 'DEP_TIME')\n",
    "encDeptTime19=leDeptTime.fit_transform(ids)\n",
    "le_dictDeptTime19 = dict(zip(leDeptTime.classes_, leDeptTime.transform(leDeptTime.classes_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ENCODINGS 2020\n",
    "\n",
    "leOrigin = preprocessing.LabelEncoder()\n",
    "ids = encoding('2020', 'ORIGIN')\n",
    "encOrigin20 =leOrigin.fit_transform(ids)\n",
    "\n",
    "le_dictOrigin20 = dict(zip(leOrigin.classes_, leOrigin.transform(leOrigin.classes_)))\n",
    "\n",
    "leDeptTime = preprocessing.LabelEncoder()\n",
    "ids = encoding('2020', 'DEP_TIME')\n",
    "encDeptTime20=leDeptTime.fit_transform(ids)\n",
    "le_dictDeptTime20 = dict(zip(leDeptTime.classes_, leDeptTime.transform(leDeptTime.classes_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X19 = collection.find({'YEAR':'2019'},{'_id':0})\n",
    "Y19 = collection.find({'YEAR':'2019'},{'_id':0,'DEP_DELAY_GROUP':1})\n",
    "# print(Y19.count())\n",
    "# print(X19.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X20 = collection.find({'YEAR':'2020'},{'_id':0})\n",
    "Y20 = collection.find({'YEAR':'2020'},{'_id':0,'DEP_DELAY_GROUP':1})\n",
    "# print(Y20.count())\n",
    "# print(X20.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019 Number of mislabeled points out of a total 322676 points : 134531\n",
      "2019 Accuracy: 0.5830771423967075\n"
     ]
    }
   ],
   "source": [
    "ids = []\n",
    "for doc in Y19:\n",
    "    ids+=[float(doc.get('DEP_DELAY_GROUP'))]\n",
    "\n",
    "labels19 = np.array(ids)\n",
    "\n",
    "i=0\n",
    "xs = []\n",
    "for doc in X19:\n",
    "    xs.append([encOrigin19.item(i), encDeptTime19.item(i)])\n",
    "    i+=1\n",
    "\n",
    "features19 = np.array(xs)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(features19, labels19, test_size=0.5, random_state=109)\n",
    "\n",
    "gnb19 = GaussianNB()\n",
    "gnb19.fit(x_train, y_train)\n",
    "\n",
    "y_pred = gnb19.predict(x_test)\n",
    "\n",
    "print(\"2019 Number of mislabeled points out of a total %d points : %d\"\n",
    "      % (x_test.shape[0], (y_test != y_pred).sum()))\n",
    "\n",
    "print(\"2019 Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = []\n",
    "for doc in Y20:\n",
    "    ids+=[float(doc.get('DEP_DELAY_GROUP'))]\n",
    "\n",
    "labels20 = np.array(ids)\n",
    "\n",
    "i=0\n",
    "xs = []\n",
    "for doc in X20:\n",
    "    xs.append([encOrigin20.item(i), encDeptTime20.item(i)])\n",
    "    i+=1\n",
    "\n",
    "features20 = np.array(xs)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(features20, labels20, test_size=0.5, random_state=109)\n",
    "\n",
    "gnb20 = GaussianNB()\n",
    "gnb20.fit(x_train, y_train)\n",
    "\n",
    "y_pred = gnb20.predict(x_test)\n",
    "\n",
    "print(\"2020 Number of mislabeled points out of a total %d points : %d\"\n",
    "      % (x_test.shape[0], (y_test != y_pred).sum()))\n",
    "\n",
    "print(\"2020 Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictFlight(origin, dest, depTime):\n",
    "    originAirport = le_dictOrigin19.get(origin, '<Unknown>')\n",
    "    #destAirport = le_dict\n",
    "    departureTime = le_dictDeptTime19.get(depTime, '')\n",
    "    features19 = np.array([[originAirport,departureTime ]])\n",
    "    \n",
    "    originAirport = le_dictOrigin20.get(origin, '<Unknown>')\n",
    "    #destAirport = le_dict\n",
    "    departureTime = le_dictDeptTime20.get(depTime, '')\n",
    "    features20 = np.array([[originAirport,departureTime ]])\n",
    "    print('Pre-Covid')\n",
    "    print(gnb19.predict(features19))\n",
    "    \n",
    "    print()\n",
    "    print('Covid')\n",
    "    print(gnb20.predict(features20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictFlight('BOS', 'DEN', '2020')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xBdp-_AC4oZW"
   },
   "source": [
    "*Linear Regression*\n",
    "\n",
    "X/Explanatory Variable\n",
    "\n",
    "*   Origin City\n",
    "\n",
    "\n",
    "\n",
    "Y/Dependent Variable\n",
    "\n",
    "\n",
    "*   Delay Time\n",
    "\n",
    "\n",
    "https://stackoverflow.com/questions/43288550/iopub-data-rate-exceeded-in-jupyter-notebook-when-viewing-image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H7GcGr6y237Z",
    "outputId": "5e414e34-5b80-4071-fafa-4f962cd6e561"
   },
   "outputs": [],
   "source": [
    "# Preparing data for Linear Regression\n",
    "#ORIGIN_AIRPORT_ID\n",
    "X = collection.find({'YEAR':'2019'},{'_id':0,'DEST_AIRPORT_ID':1})\n",
    "Y = collection.find({'YEAR':'2019'},{'_id':0,'ARR_DELAY':1})\n",
    "\n",
    "ids = []\n",
    "for doc in Y:\n",
    "    ids+=[float(doc.get('ARR_DELAY'))]\n",
    "\n",
    "Y = np.array(ids)\n",
    "\n",
    "xs = []\n",
    "for doc in X:\n",
    "    xs.append([int(doc.get('DEST_AIRPORT_ID'))]) #,int(doc.get( 'DEST_AIRPORT_ID'))])\n",
    "\n",
    "X = np.array(xs)\n",
    "x_train, x_test, y_train, y_test = train_test_split(X,Y, test_size=0.3)\n",
    "regr = LinearRegression()\n",
    "regr.fit(x_train, y_train)\n",
    "\n",
    "y_pred = regr.predict(x_test)\n",
    "\n",
    "# example from : https://scikit-learn.org/stable/auto_examples/linear_model/plot_ols.html\n",
    "\n",
    "# The coefficients\n",
    "print('Coefficients: \\n', regr.coef_)\n",
    "# The mean squared error\n",
    "print('Mean squared error: %.2f'\n",
    "      % mean_squared_error(y_test, y_pred))\n",
    "# The coefficient of determination: 1 is perfect prediction\n",
    "print('Coefficient of determination: %.2f'\n",
    "      % r2_score(y_test, y_pred))\n",
    "\n",
    "#print('Accuracy: ', accuracy_score(y_test, y_pred) )\n",
    "# Plot outputs\n",
    "plt.scatter(x_test, y_test)\n",
    "plt.plot(x_test, y_pred, color='blue', linewidth=3)\n",
    "\n",
    "plt.xticks(())\n",
    "plt.yticks(())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(list(collection.find({'YEAR':'2019', 'DAY_OF_MONTH': '25'})))\n",
    "\n",
    "X = df[{'YEAR':'2019', 'DAY_OF_MONTH': '25'},{'_id':0,'ORIGIN_AIRPORT_ID':1, 'DEST_AIRPORT_ID':1}]\n",
    "Y = df[{'YEAR':'2019', 'DAY_OF_MONTH': '25'},{'_id':0,'DEP_DELAY_GROUP':1}]\n",
    "x, y = np.array(X), np.array(Y)\n",
    "\n",
    "\n",
    "regr = linear_model.LinearRegression()\n",
    "regr.fit(X, y)\n",
    "\n",
    "predictedCO2 = regr.predict([['11292','13232']])\n",
    "\n",
    "print(x)\n",
    "print(y)\n",
    "\n",
    "model = LinearRegression().fit(x, y)\n",
    "r_sq = model.score(x, y)\n",
    "print('coefficient of determination:', r_sq)\n",
    "print('intercept:', model.intercept_)\n",
    "print('slope:', model.coef_)\n",
    "\n",
    "y_pred = model.predict(x)\n",
    "print('predicted response:', y_pred, sep='\\n')\n",
    "\n",
    "y_pred = model.intercept_ + np.sum(model.coef_ * x, axis=1)\n",
    "\n",
    "\n",
    "print('predicted response:', y_pred, sep='\\n')\n",
    "\n",
    "x_new = np.arange(10).reshape((-1, 2))\n",
    "print(x_new)\n",
    "\n",
    "y_new = model.predict(x_new)\n",
    "print(y_new)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preCovidOC = collection.find({'YEAR':'2019'},{'_id':0,'ORIGIN_CITY_NAME':1})\n",
    "#X = np.array(preCovidOC)\n",
    "X = collection.find({'YEAR':'2019', 'DAY_OF_MONTH': '25'},{'_id':0,'ORIGIN_AIRPORT_ID':1, 'DEST_AIRPORT_ID':1})\n",
    "#print(X)\n",
    "Y = collection.find({'YEAR':'2019', 'DAY_OF_MONTH': '25'},{'_id':0,'DEP_DELAY_GROUP':1})\n",
    "df = pd.DataFrame(list(collection.find({'YEAR':'2019', 'DAY_OF_MONTH': '25'})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = []\n",
    "for doc in Y:\n",
    "    ids+=[float(doc.get('DEP_DELAY_GROUP'))]\n",
    "Y = np.array(ids)\n",
    "#print(Y)\n",
    "#print(len(Y))\n",
    "xs = []\n",
    "for doc in X:\n",
    "    xs.append([int(doc.get('ORIGIN_AIRPORT_ID'))])#,int(doc.get( 'DEST_AIRPORT_ID'))])\n",
    "X = np.array(xs)\n",
    "#print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train2, x_test2, y_train2, y_test2 = train_test_split(X,Y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error: Lin: 69862030.02\n",
      "[ 5635.73750534 14549.95825424 12421.78843345 ...  -231.78729973\n",
      " 11553.45499458 12923.715279  ]\n",
      "Number of mislabeled points out of a total 6302 points : Linear kernel :  6297\n",
      "Accuracy Score: Linear kernel : 0.0007933989209774674\n"
     ]
    }
   ],
   "source": [
    "svr_lin = SVR(kernel = 'linear')\n",
    "svr_lin.fit(x_train2, y_train2)\n",
    "y_predLin = svr_lin.predict(x_test2)\n",
    "print('Mean squared error: Lin: %.2f'\n",
    "      % mean_squared_error(y_test2, y_predLin))\n",
    "print(y_predLin)\n",
    "print(\"Number of mislabeled points out of a total %d points : Linear kernel :  %d\"\n",
    "      % (x_test2.shape[0], (y_test2 != np.round(y_predLin)).sum()))\n",
    "\n",
    "#accuracy_score not working, calculate manually\n",
    "acc_lin = (y_test2 == np.round(y_predLin)).sum()/x_test2.shape[0]\n",
    "\n",
    "print('Accuracy Score: Linear kernel : '\n",
    " #     % accuracy_score(y_test2, y_predLin))\n",
    "     + str(acc_lin))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Poly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svr_poly = SVR(kernel = 'poly')\n",
    "svr_poly.fit(x_train2, y_train2)\n",
    "y_predPoly = svr_poly.predict(x_test2)\n",
    "print('Mean squared error: Poly: %.2f'\n",
    "      % mean_squared_error(y_test2, y_predPoly))\n",
    "\n",
    "print(\"Number of mislabeled points out of a total %d points : Polynomial kernel :  %d\"\n",
    "      % (x_test2.shape[0], (y_test2 != np.round(y_predPoly)).sum()))\n",
    "print('Coefficient of determination: Polynomial:  %.2f'\n",
    "      % r2_score(y_test2, y_predPoly))\n",
    "\n",
    "acc_poly = (y_test2 == np.round(y_predPoly)).sum()/x_test2.shape[0]\n",
    "print('Accuracy Score: Polynomial kernel :'\n",
    "      + str(acc_poly))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RBF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svr_rbf = SVR(kernel = 'rbf')\n",
    "svr_rbf.fit(x_train2, y_train2)\n",
    "y_predRbf = svr_rbf.predict(x_test2)\n",
    "\n",
    "print('Mean squared error: RBF: %.2f'\n",
    "      % mean_squared_error(y_test2, y_predRbf))\n",
    "\n",
    "print(y_predRbf)\n",
    "\n",
    "#np.round makes it correct, i think since SVR is a regression, it tries to extimate exactly, which is'nt an integer\n",
    "\n",
    "print(\"Number of mislabeled points out of a total %d points : RBF kernel :  %d\"\n",
    "      % (x_test2.shape[0], (y_test2 != np.round(y_predRbf)).sum()))\n",
    "\n",
    "\n",
    "print('Coefficient of determination: RBF:  %.2f'\n",
    "      % r2_score(y_test2, y_predRbf))\n",
    "\n",
    "acc_rbf = (y_test2 == np.round(y_predRbf)).sum()/x_test2.shape[0]\n",
    "\n",
    "print('Accuracy Score: RBF kernel :'\n",
    "      + str(acc_rbf))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[-0.90016884 -0.90020146 -0.90046147 ... -0.89962424 -0.90009629\n",
    " -0.899679  ]\n",
    " \n",
    "Number of mislabeled points out of a total 6302 points : Linear kernel :  6302\n",
    "\n",
    "Number of mislabeled points out of a total 6302 points : Polynomial kernel :  5652\n",
    "\n",
    "Number of mislabeled points out of a total 6302 points : RBF kernel :  1959\n",
    "\n",
    "Coefficient of determination: Linear:  -23340845.91\n",
    "\n",
    "Coefficient of determination: Polynomial:  -1.31\n",
    "\n",
    "Coefficient of determination: RBF:  -0.12\n",
    "\n",
    "Accuracy Score: Linear kernel : 0.0\n",
    "\n",
    "Accuracy Score: Polynomial kernel :0.10314185972707077\n",
    "\n",
    "Accuracy Score: RBF kernel :0.6891463027610283\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Final Project.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
