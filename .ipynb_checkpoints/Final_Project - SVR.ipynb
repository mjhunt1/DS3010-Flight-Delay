{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rdeo6F7vRrbf"
   },
   "source": [
    "Flight Analysis\n",
    "\n",
    "Profs notes on the draft: Excellent plan. It will be great to report/show pre-COVID vs. after-COVID analysis (and... even during the COVID in each month/quarterly). You can also try both linear and non-linear regression models (e.g., linear regression and SVR regression with nonlinear kernel). https://scikit-learn.org/stable/auto_examples/svm/plot_svm_regression.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sZLmdTAeR8J2"
   },
   "source": [
    "The data: \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "agyrsdlnzozr"
   },
   "source": [
    "**All imports needed to run**\n",
    "\n",
    "If the next snippet fails, go into Runtime>> Restars Runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "469uSGAKREZ-",
    "outputId": "d4abef10-1f74-4926-db78-cb8540380739"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pymongo in c:\\users\\maxhu\\anaconda3\\lib\\site-packages (3.11.3)\n",
      "Requirement already satisfied: dnspython==2.1.0 in c:\\users\\maxhu\\anaconda3\\lib\\site-packages (2.1.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\maxhu\\anaconda3\\lib\\site-packages (0.24.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\maxhu\\anaconda3\\lib\\site-packages (from scikit-learn) (2.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\maxhu\\anaconda3\\lib\\site-packages (from scikit-learn) (0.17.0)\n",
      "Requirement already satisfied: numpy>=1.13.3 in c:\\users\\maxhu\\anaconda3\\lib\\site-packages (from scikit-learn) (1.19.2)\n",
      "Requirement already satisfied: scipy>=0.19.1 in c:\\users\\maxhu\\anaconda3\\lib\\site-packages (from scikit-learn) (1.5.2)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install pymongo\n",
    "!{sys.executable} -m pip install dnspython==2.1.0\n",
    "!{sys.executable} -m pip install scikit-learn\n",
    "#!{sys.executable} -m pip install pymongo[srv]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p1owAQjB0Fl2"
   },
   "source": [
    "**Importing Data into MongoDB**\n",
    "\n",
    "We downloaded the data from the website <<INSERT HERE>>\n",
    "\n",
    "We tried loading it through Drive/Google Drive to MongoDB. However, our notebook was not able to handle the amount of data, because it ran out of space.\n",
    "\n",
    "So we used, MongoDB Compass to upload the existing CSVs to our collection\n",
    "    \n",
    "We made a duplicate of the original datatset, because our work requires deleting some values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h5k1Ojmuz9s2"
   },
   "source": [
    "**Connecting to MongoDB**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "VL4X4n-RWFnz"
   },
   "outputs": [],
   "source": [
    "# RUN\n",
    "import pymongo\n",
    "import dns\n",
    "\n",
    "client = pymongo.MongoClient(\"mongodb+srv://dbUser:test123@cluster0.92wx0.mongodb.net/finalProject?retryWrites=true&w=majority\")\n",
    "\n",
    "db = client['finalProject']\n",
    "\n",
    "collection = db['flightData']\n",
    "\n",
    "# pipeline = [ {\"$match\": {}}, {\"$out\": \"anotheDuplicate\"},]\n",
    "# collection.aggregate(pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DELETING DATA**\n",
    "Deleting the data, which has no values for any of the analysis factors needed below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pymongo.results.DeleteResult at 0x185f30d8980>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#, 'DEST_AIRPORT_ID':{ $exists : false } ,'DEP_DELAY':{ $exists : false }\n",
    "collection.delete_many({'MONTH' : '6' } )\n",
    "collection.delete_many({'MONTH' : '7' } )\n",
    "collection.delete_many({'DEP_DELAY' : {'$eq': None}} )\n",
    "collection.delete_many({'YEAR' : {'$eq': None}} )\n",
    "collection.delete_many({'ORIGIN_AIRPORT_ID' : {'$eq': None}} )\n",
    "collection.delete_many({'DEST_AIRPORT_ID' : {'$eq': None}} )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1019768\n"
     ]
    }
   ],
   "source": [
    "print(collection.count_documents({}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QszVHK_U0rS4"
   },
   "source": [
    "**Looking at Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5vcKD-yAwsvp",
    "outputId": "7973b39c-2e21-4331-9e3d-b4fd73060f40",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of data for Pre-Covid: June, July, August of 2019\n",
      "646998\n",
      "\n",
      "Number of data for Covid: June, July, August of 2020\n",
      "372770\n",
      "\n",
      "Example of one data point\n",
      "{'_id': ObjectId('608de2ba9c0bff4d24c42081'), 'YEAR': '2019', 'QUARTER': '3', 'MONTH': '8', 'DAY_OF_MONTH': '25', 'DAY_OF_WEEK': '7', 'FL_DATE': '2019-08-25', 'OP_UNIQUE_CARRIER': 'WN', 'TAIL_NUM': 'N433LV', 'OP_CARRIER_FL_NUM': '4349', 'ORIGIN_AIRPORT_ID': '11292', 'ORIGIN_AIRPORT_SEQ_ID': '1129202', 'ORIGIN_CITY_MARKET_ID': '30325', 'ORIGIN': 'DEN', 'ORIGIN_CITY_NAME': 'Denver, CO', 'ORIGIN_STATE_ABR': 'CO', 'ORIGIN_STATE_NM': 'Colorado', 'DEST_AIRPORT_ID': '13232', 'DEST_AIRPORT_SEQ_ID': '1323202', 'DEST_CITY_MARKET_ID': '30977', 'DEST': 'MDW', 'DEST_CITY_NAME': 'Chicago, IL', 'DEST_STATE_ABR': 'IL', 'DEST_STATE_NM': 'Illinois', 'CRS_DEP_TIME': '2150', 'DEP_TIME': '2150', 'DEP_DELAY': '0.00', 'DEP_DELAY_NEW': '0.00', 'DEP_DEL15': '0.00', 'DEP_DELAY_GROUP': '0', 'DEP_TIME_BLK': '2100-2159', 'TAXI_OUT': '12.00', 'WHEELS_OFF': '2202', 'WHEELS_ON': '0049', 'TAXI_IN': '3.00', 'CRS_ARR_TIME': '0105', 'ARR_TIME': '0052', 'ARR_DELAY': '-13.00', 'ARR_DELAY_NEW': '0.00', 'ARR_DEL15': '0.00', 'ARR_DELAY_GROUP': '-1', 'ARR_TIME_BLK': '0001-0559', 'CANCELLED': '0.00', 'DIVERTED': '0.00', 'CRS_ELAPSED_TIME': '135.00', 'ACTUAL_ELAPSED_TIME': '122.00', 'DISTANCE': '895.00', 'DISTANCE_GROUP': '4'}\n"
     ]
    }
   ],
   "source": [
    "#Just Checking\n",
    "\n",
    "allPreCovid = collection.find({'YEAR':'2019'})\n",
    "allCovid = collection.find({'YEAR':'2020'})\n",
    "\n",
    "print(\"Number of data for Pre-Covid: June, July, August of 2019\")\n",
    "#print(allPreCovid.count())\n",
    "print(collection.count_documents({'YEAR':'2019'}))\n",
    "\n",
    "print()\n",
    "print(\"Number of data for Covid: June, July, August of 2020\")\n",
    "#print(allCovid.count())\n",
    "print(collection.count_documents({'YEAR':'2020'}))\n",
    "\n",
    "print()\n",
    "print(\"Example of one data point\")\n",
    "print(collection.find_one())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vh7ZJs5B2wWr"
   },
   "source": [
    "**Analyzing**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xBdp-_AC4oZW"
   },
   "source": [
    "\n",
    "\n",
    "\n",
    "https://stackoverflow.com/questions/43288550/iopub-data-rate-exceeded-in-jupyter-notebook-when-viewing-image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H7GcGr6y237Z",
    "outputId": "5e414e34-5b80-4071-fafa-4f962cd6e561"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.svm import SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#https://scikit-learn.org/stable/auto_examples/linear_model/plot_ols.html\n",
    "#import matplotlib.pyplot as plt\n",
    "#from sklearn.metrics import mean_squared_error, r2_score\n",
    "# The coefficients\n",
    "#print('Coefficients: \\n', regr.coef_)\n",
    "# The mean squared error\n",
    "#print('Mean squared error: %.2f'\n",
    "#      % mean_squared_error(y_test, y_pred))\n",
    "# The coefficient of determination: 1 is perfect prediction\n",
    "#print('Coefficient of determination: %.2f'\n",
    "#      % r2_score(y_test, y_pred))\n",
    "\n",
    "# Plot outputs\n",
    "#plt.scatter(x_test, y_test)\n",
    "#plt.plot(x_test, y_pred, color='blue', linewidth=3)\n",
    "\n",
    "#plt.xticks(())\n",
    "#plt.yticks(())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preCovidOC = collection.find({'YEAR':'2019'},{'_id':0,'ORIGIN_CITY_NAME':1})\n",
    "#X = np.array(preCovidOC)\n",
    "X = collection.find({'YEAR':'2019', 'DAY_OF_MONTH': '25'},{'_id':0,'ORIGIN_AIRPORT_ID':1, 'DEST_AIRPORT_ID':1})\n",
    "#print(X)\n",
    "Y = collection.find({'YEAR':'2019', 'DAY_OF_MONTH': '25'},{'_id':0,'DEP_DELAY_GROUP':1})\n",
    "df = pd.DataFrame(list(collection.find({'YEAR':'2019', 'DAY_OF_MONTH': '25'})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = []\n",
    "for doc in Y:\n",
    "    ids+=[float(doc.get('DEP_DELAY_GROUP'))]\n",
    "Y = np.array(ids)\n",
    "#print(Y)\n",
    "#print(len(Y))\n",
    "xs = []\n",
    "for doc in X:\n",
    "    xs.append([int(doc.get('ORIGIN_AIRPORT_ID'))])#,int(doc.get( 'DEST_AIRPORT_ID'))])\n",
    "X = np.array(xs)\n",
    "#print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train2, x_test2, y_train2, y_test2 = train_test_split(X,Y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "svr_lin = SVR(kernel = 'linear')\n",
    "svr_poly = SVR(kernel = 'poly')\n",
    "svr_rbf = SVR(kernel = 'rbf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVR()"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svr_lin.fit(x_train2, y_train2)\n",
    "svr_poly.fit(x_train2, y_train2)\n",
    "svr_rbf.fit(x_train2, y_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predPoly = svr_poly.predict(x_test2)\n",
    "y_predLin = svr_lin.predict(x_test2)\n",
    "y_predRbf = svr_rbf.predict(x_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error: 4.64\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "print('Mean squared error: %.2f'\n",
    "      % mean_squared_error(y_test2, y_pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.90016884 -0.90020146 -0.90046147 ... -0.89962424 -0.90009629\n",
      " -0.899679  ]\n",
      "Number of mislabeled points out of a total 6302 points : Linear kernel :  6302\n",
      "Number of mislabeled points out of a total 6302 points : Polynomial kernel :  5652\n",
      "Number of mislabeled points out of a total 6302 points : RBF kernel :  1959\n",
      "Coefficient of determination: Linear:  -23340845.91\n",
      "Coefficient of determination: Polynomial:  -1.31\n",
      "Coefficient of determination: RBF:  -0.12\n",
      "Accuracy Score: Linear kernel : 0.0\n",
      "Accuracy Score: Polynomial kernel :0.10314185972707077\n",
      "Accuracy Score: RBF kernel :0.6891463027610283\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score, accuracy_score\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "print(y_predRbf)\n",
    "\n",
    "#np.round makes it correct, i think since SVR is a regression, it tries to extimate exactly, which is'nt an integer\n",
    "print(\"Number of mislabeled points out of a total %d points : Linear kernel :  %d\"\n",
    "      % (x_test2.shape[0], (y_test2 != np.round(y_predLin)).sum()))\n",
    "print(\"Number of mislabeled points out of a total %d points : Polynomial kernel :  %d\"\n",
    "      % (x_test2.shape[0], (y_test2 != np.round(y_predPoly)).sum()))\n",
    "print(\"Number of mislabeled points out of a total %d points : RBF kernel :  %d\"\n",
    "      % (x_test2.shape[0], (y_test2 != np.round(y_predRbf)).sum()))\n",
    "print('Coefficient of determination: Linear:  %.2f'\n",
    "      % r2_score(y_test2, y_predLin))\n",
    "print('Coefficient of determination: Polynomial:  %.2f'\n",
    "      % r2_score(y_test2, y_predPoly))\n",
    "print('Coefficient of determination: RBF:  %.2f'\n",
    "      % r2_score(y_test2, y_predRbf))\n",
    "#accuracy_score not working, calculate manually\n",
    "acc_lin = (y_test2 == np.round(y_predLin)).sum()/x_test2.shape[0]\n",
    "acc_poly = (y_test2 == np.round(y_predPoly)).sum()/x_test2.shape[0]\n",
    "acc_rbf = (y_test2 == np.round(y_predRbf)).sum()/x_test2.shape[0]\n",
    "print('Accuracy Score: Linear kernel : '\n",
    "#     % accuracy_score(y_test2, y_predLin))\n",
    "      + str(acc_lin))\n",
    "print('Accuracy Score: Polynomial kernel :'\n",
    "      + str(acc_poly))\n",
    "print('Accuracy Score: RBF kernel :'\n",
    "      + str(acc_rbf))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[-0.90016884 -0.90020146 -0.90046147 ... -0.89962424 -0.90009629\n",
    " -0.899679  ]\n",
    " \n",
    "Number of mislabeled points out of a total 6302 points : Linear kernel :  6302\n",
    "\n",
    "Number of mislabeled points out of a total 6302 points : Polynomial kernel :  5652\n",
    "\n",
    "Number of mislabeled points out of a total 6302 points : RBF kernel :  1959\n",
    "\n",
    "Coefficient of determination: Linear:  -23340845.91\n",
    "\n",
    "Coefficient of determination: Polynomial:  -1.31\n",
    "\n",
    "Coefficient of determination: RBF:  -0.12\n",
    "\n",
    "Accuracy Score: Linear kernel : 0.0\n",
    "\n",
    "Accuracy Score: Polynomial kernel :0.10314185972707077\n",
    "\n",
    "Accuracy Score: RBF kernel :0.6891463027610283\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Final Project.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
