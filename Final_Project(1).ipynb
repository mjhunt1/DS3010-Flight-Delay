{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rdeo6F7vRrbf"
   },
   "source": [
    "Flight Analysis\n",
    "\n",
    "Profs notes on the draft: Excellent plan. It will be great to report/show pre-COVID vs. after-COVID analysis (and... even during the COVID in each month/quarterly). You can also try both linear and non-linear regression models (e.g., linear regression and SVR regression with nonlinear kernel). https://scikit-learn.org/stable/auto_examples/svm/plot_svm_regression.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sZLmdTAeR8J2"
   },
   "source": [
    "The data: \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "agyrsdlnzozr"
   },
   "source": [
    "**All imports needed to run**\n",
    "\n",
    "If the next snippet fails, go into Runtime>> Restars Runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "469uSGAKREZ-",
    "outputId": "d4abef10-1f74-4926-db78-cb8540380739"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install pymongo\n",
    "!{sys.executable} -m pip install dnspython==2.1.0\n",
    "!{sys.executable} -m pip install scikit-learn\n",
    "#!{sys.executable} -m pip install pymongo[srv]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p1owAQjB0Fl2"
   },
   "source": [
    "**Importing Data into MongoDB**\n",
    "\n",
    "We downloaded the data from the website <<INSERT HERE>>\n",
    "\n",
    "We tried loading it through Drive/Google Drive to MongoDB. However, our notebook was not able to handle the amount of data, because it ran out of space.\n",
    "\n",
    "So we used, MongoDB Compass to upload the existing CSVs to our collection\n",
    "    \n",
    "We made a duplicate of the original datatset, because our work requires deleting some values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h5k1Ojmuz9s2"
   },
   "source": [
    "**Connecting to MongoDB**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "VL4X4n-RWFnz"
   },
   "outputs": [],
   "source": [
    "# RUN\n",
    "import pymongo\n",
    "import dns\n",
    "\n",
    "client = pymongo.MongoClient(\"mongodb+srv://dbUser:test123@cluster0.92wx0.mongodb.net/finalProject?retryWrites=true&w=majority\")\n",
    "\n",
    "db = client['finalProject']\n",
    "\n",
    "collection = db['flightData']\n",
    "\n",
    "# pipeline = [ {\"$match\": {}}, {\"$out\": \"anotheDuplicate\"},]\n",
    "# collection.aggregate(pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DELETING DATA**\n",
    "Deleting the data, which has no values for any of the analysis factors needed below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pymongo.results.DeleteResult at 0x20e37ee5b00>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#, 'DEST_AIRPORT_ID':{ $exists : false } ,'DEP_DELAY':{ $exists : false }\n",
    "collection.delete_many({'MONTH' : '6' } )\n",
    "collection.delete_many({'MONTH' : '7' } )\n",
    "\n",
    "collection.delete_many({'DEP_DELAY' : {'$eq': None}} )\n",
    "collection.delete_many({'DEP_DELAY_GROUP' : {'$eq': None}} )\n",
    "\n",
    "\n",
    "collection.delete_many({'YEAR' : {'$eq': None}} )\n",
    "collection.delete_many({'ORIGIN_AIRPORT_ID' : {'$eq': None}} )\n",
    "collection.delete_many({'DEST_AIRPORT_ID' : {'$eq': None}} )\n",
    "collection.delete_many({'DEP_TIME' : {'$eq': None}} )\n",
    "collection.delete_many({'ARR_TIME' : {'$eq': None}} )\n",
    "\n",
    "collection.delete_many({'ORIGIN' : {'$eq': None}} )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1019768\n"
     ]
    }
   ],
   "source": [
    "print(collection.count_documents({}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QszVHK_U0rS4"
   },
   "source": [
    "**Looking at Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5vcKD-yAwsvp",
    "outputId": "7973b39c-2e21-4331-9e3d-b4fd73060f40"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of data for Pre-Covid: June, July, August of 2019\n",
      "646998\n",
      "\n",
      "Number of data for Covid: June, July, August of 2020\n",
      "372770\n",
      "\n",
      "Example of one data point\n",
      "{'_id': ObjectId('608de2ba9c0bff4d24c42081'), 'YEAR': '2019', 'QUARTER': '3', 'MONTH': '8', 'DAY_OF_MONTH': '25', 'DAY_OF_WEEK': '7', 'FL_DATE': '2019-08-25', 'OP_UNIQUE_CARRIER': 'WN', 'TAIL_NUM': 'N433LV', 'OP_CARRIER_FL_NUM': '4349', 'ORIGIN_AIRPORT_ID': '11292', 'ORIGIN_AIRPORT_SEQ_ID': '1129202', 'ORIGIN_CITY_MARKET_ID': '30325', 'ORIGIN': 'DEN', 'ORIGIN_CITY_NAME': 'Denver, CO', 'ORIGIN_STATE_ABR': 'CO', 'ORIGIN_STATE_NM': 'Colorado', 'DEST_AIRPORT_ID': '13232', 'DEST_AIRPORT_SEQ_ID': '1323202', 'DEST_CITY_MARKET_ID': '30977', 'DEST': 'MDW', 'DEST_CITY_NAME': 'Chicago, IL', 'DEST_STATE_ABR': 'IL', 'DEST_STATE_NM': 'Illinois', 'CRS_DEP_TIME': '2150', 'DEP_TIME': '2150', 'DEP_DELAY': '0.00', 'DEP_DELAY_NEW': '0.00', 'DEP_DEL15': '0.00', 'DEP_DELAY_GROUP': '0', 'DEP_TIME_BLK': '2100-2159', 'TAXI_OUT': '12.00', 'WHEELS_OFF': '2202', 'WHEELS_ON': '0049', 'TAXI_IN': '3.00', 'CRS_ARR_TIME': '0105', 'ARR_TIME': '0052', 'ARR_DELAY': '-13.00', 'ARR_DELAY_NEW': '0.00', 'ARR_DEL15': '0.00', 'ARR_DELAY_GROUP': '-1', 'ARR_TIME_BLK': '0001-0559', 'CANCELLED': '0.00', 'DIVERTED': '0.00', 'CRS_ELAPSED_TIME': '135.00', 'ACTUAL_ELAPSED_TIME': '122.00', 'DISTANCE': '895.00', 'DISTANCE_GROUP': '4'}\n"
     ]
    }
   ],
   "source": [
    "#Just Checking\n",
    "import json\n",
    "\n",
    "allPreCovid = collection.find({'YEAR':'2019'})\n",
    "allCovid = collection.find({'YEAR':'2020'})\n",
    "\n",
    "print(\"Number of data for Pre-Covid: June, July, August of 2019\")\n",
    "#print(allPreCovid.count())\n",
    "print(collection.count_documents({'YEAR':'2019'}))\n",
    "\n",
    "print()\n",
    "print(\"Number of data for Covid: June, July, August of 2020\")\n",
    "#print(allCovid.count())\n",
    "print(collection.count_documents({'YEAR':'2020'}))\n",
    "\n",
    "print()\n",
    "print(\"Example of one data point\")\n",
    "print(collection.find_one())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vh7ZJs5B2wWr"
   },
   "source": [
    "**Analyzing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "#from sklearn.cluster import KMeans\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Gaussian Naive Bayes*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "features: Dep_time and arr_time\n",
    "label: dep_delay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Encoder\n",
    "import joblib\n",
    "\n",
    "import pickle\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "origin = collection.find({'YEAR':'2019'},{'_id':0,'ORIGIN':1})\n",
    "ids = []\n",
    "for doc in origin:\n",
    "    ids+=[(doc.get('ORIGIN'))]\n",
    "\n",
    "enc=le.fit_transform(ids)\n",
    "\n",
    "le_dict = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "#joblib.dump(le,'scaler.bin')\n",
    "# print (enc)\n",
    "# print (len(enc))\n",
    "# print(enc.shape)\n",
    "# print(type(enc))\n",
    "# print(enc.item(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le_dict.get('DEN', '<Unknown>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = collection.find({'YEAR':'2019'},{'_id':0,'DEP_TIME':1})\n",
    "Y = collection.find({'YEAR':'2019'},{'_id':0,'DEP_DELAY_GROUP':1})\n",
    "\n",
    "ids = []\n",
    "for doc in Y:\n",
    "    ids+=[float(doc.get('DEP_DELAY_GROUP'))]\n",
    "\n",
    "labels = np.array(ids)\n",
    "\n",
    "print(X.count())\n",
    "i=0\n",
    "xs = []\n",
    "for doc in X:\n",
    "    xs.append([int(doc.get('DEP_TIME')),enc.item(i)])\n",
    "    i+=1\n",
    "\n",
    "features = np.array(xs)\n",
    "# print(features)\n",
    "# print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(features, labels, test_size=0.5, random_state=109)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb = GaussianNB()\n",
    "gnb.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_test)\n",
    "y_pred = gnb.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of mislabeled points out of a total %d points : %d\"\n",
    "      % (x_test.shape[0], (y_test != y_pred).sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PREDICT NEW\n",
    "\n",
    "scheduled = '2080'\n",
    "airport = le_dict.get('DEN', '<Unknown>')\n",
    "features = np.array([[int(scheduled), airport]])\n",
    "\n",
    "print(gnb.predict(features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xBdp-_AC4oZW"
   },
   "source": [
    "*Linear Regression*\n",
    "\n",
    "X/Explanatory Variable\n",
    "\n",
    "*   Origin City\n",
    "\n",
    "\n",
    "\n",
    "Y/Dependent Variable\n",
    "\n",
    "\n",
    "*   Delay Time\n",
    "\n",
    "\n",
    "https://stackoverflow.com/questions/43288550/iopub-data-rate-exceeded-in-jupyter-notebook-when-viewing-image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H7GcGr6y237Z",
    "outputId": "5e414e34-5b80-4071-fafa-4f962cd6e561"
   },
   "outputs": [],
   "source": [
    "# Preparing data for Linear Regression\n",
    "X = collection.find({'YEAR':'2019'},{'_id':0,'ORIGIN_AIRPORT_ID':1, 'DEST_AIRPORT_ID':1})\n",
    "Y = collection.find({'YEAR':'2019'},{'_id':0,'DEP_DELAY':1})\n",
    "\n",
    "ids = []\n",
    "for doc in Y:\n",
    "    ids+=[float(doc.get('DEP_DELAY'))]\n",
    "\n",
    "Y = np.array(ids)\n",
    "\n",
    "xs = []\n",
    "for doc in X:\n",
    "    xs.append([int(doc.get('ORIGIN_AIRPORT_ID'))])#,int(doc.get( 'DEST_AIRPORT_ID'))])\n",
    "\n",
    "X = np.array(xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X,Y, test_size=0.3)\n",
    "regr = LinearRegression()\n",
    "regr.fit(x_train, y_train)\n",
    "\n",
    "y_pred = regr.predict(x_test)\n",
    "\n",
    "# example from : https://scikit-learn.org/stable/auto_examples/linear_model/plot_ols.html\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "# The coefficients\n",
    "print('Coefficients: \\n', regr.coef_)\n",
    "# The mean squared error\n",
    "print('Mean squared error: %.2f'\n",
    "      % mean_squared_error(y_test, y_pred))\n",
    "# The coefficient of determination: 1 is perfect prediction\n",
    "print('Coefficient of determination: %.2f'\n",
    "      % r2_score(y_test, y_pred))\n",
    "\n",
    "# Plot outputs\n",
    "plt.scatter(x_test, y_test)\n",
    "plt.plot(x_test, y_pred, color='blue', linewidth=3)\n",
    "\n",
    "plt.xticks(())\n",
    "plt.yticks(())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Final Project.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
